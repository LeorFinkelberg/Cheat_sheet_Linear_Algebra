\documentclass[%
	11pt,
	a4paper,
	utf8,
	%twocolumn
		]{article}	

\usepackage{style_packages/podvoyskiy_article_extended}


\begin{document}
\title{Сборник заметок по линейной алгебре и сопряженным вопросам}

\author{\itshape Подвойский А.О.}

\date{}
\maketitle

\thispagestyle{fancy}


%\shorttableofcontents{Краткое содержание}{1}


\tableofcontents

\section{Мера обусловленности матрицы}

\emph{Мера} (или \emph{число}) \emph{обусловленности матрицы} $ A $ определяется как \cite[\strbook{306}]{bahvalov:num_methods}
\begin{align*}
	\nu(A) = \| A \| \, \| A^{-1} \|
\end{align*}
 
Поскольку \emph{\underline{любая} норма} матрицы не меньше своего наибольшего по модулю собственного значения, то $ \| A \| \geqslant \max | \lambda_A | $ и поскольку собственные значения матриц $ A $ и $ A^{-1} $ взаимо обратны, то
\begin{align*}
	\| A^{-1} \| \geqslant \max \dfrac{1}{ | \lambda_A | } = \dfrac{1}{ \min | \lambda_A | }
\end{align*}

Таким образом, мера обусловленности матрицы $ A $
\begin{align*}
	\boxed{\nu(A) \geqslant \dfrac{\max | \lambda_A |}{ \min | \lambda_A | } \geqslant 1}
\end{align*}

В частности, при $ A = A^T $ (то есть если матрица симметричная) имеем $ \| A \|_2 = \max | \lambda_A | $.

Следовательно, в случае нормы $ \| \cdot \|_2 $
\begin{align*}
	\nu(A) = \dfrac{ \max | \lambda_A | }{ \min | \lambda_A | }.
\end{align*}


\section{Линейно зависимые и линейно независимые системы}

Система из $ k $ столбцов $ A_1, \ldots, A_k $ называется \emph{линейно зависимой}, если существуют такие числа $ \alpha_1, \ldots, \alpha_k $ не все равные нулю одновременно, что \cite[\strbook{128}]{bortakovskiy:2005}
\begin{align*}
	\alpha_1 A_1 + \alpha_2 A_2 + \ldots \alpha_k A_k = o,
\end{align*}
где $ o $ -- нулевой вектор соответствующего размера.

То есть другими словами система $ k $ столбцов называется \emph{линейно зависимой}, если эти столбцы \emph{суммируются в нулевой столбец} для нетривиального случая коэффициентов $ \alpha_i $ (когда эти коэффициенты не все одновременно равны нулю).

Система из $ k $ столбцов называется \emph{линейно независимой}, если $ \sum\limits_{j=1}^k \alpha_j A_j = o $ возможно только в тривиальном случае, т.е. когда $ \alpha_1 = \alpha_2 = \ldots = \alpha_k = 0 $.

\subsection{Свойства линейно зависимых и линейно независимых столбцов}

\remark{
	Понятия линейной зависимости и линейной независимости формулируются одинаково как для строк, и так для столбцов
}

\begin{itemize}
	\item Если в систему входит \emph{нулевой столбец}, то она \emph{линейно зависима},
	
	\item Если в систему входит \emph{два равных столбца}, то она \emph{линейно зависима},
	
	\item Если в системе столбцов имеется два пропорциональных столбца $ A_i = \lambda A_j $, то она линейно зависима,
	
	\item Любые столбцы, входящие в \emph{линейно независимую систему}, образуют \emph{линейно независимую подсистему},
	
	\item Система столбцов, содержащая \emph{линейно зависимую подсистему}, сама \emph{линейно зависима},
	
	\item Если система столбцов $ A_1, \ldots,A_k $ -- линейно независима, а после присоединения к ней столбца $ A $ -- оказывается линейно зависимой, то столбец $ A $ можно разложить по столбцам $ A_1, \ldots, A_k $ и притом единственным образом, т.е. коэффициенты определяются однозначно.
\end{itemize}

\section{Система $ m $ линейных алгебраических уравнений с $ n $ неизвестными}

Матричная запись неоднородной системы уравнений имеет вид
\vspace*{-3mm}
\begin{align*}
	A x = b,
\end{align*}

\vspace*{-3mm}
а однородной
\vspace*{-3mm}
\begin{align*}
	A x = o,
\end{align*}

\vspace*{-3mm}
где $ o $ в правой части обозначает нулевой столбец размеров $ m \times 1 $.

Эту матричную запись неоднородной системы уравнений можно представить в эквивалентной форме
\begin{align*}
	\begin{pmatrix}
		a_{11} \\
		\vdots \\
		a_{m1}
	\end{pmatrix} x_1 + 
    \begin{pmatrix}
    	a_{12} \\
    	\vdots \\
    	a_{m2}
    \end{pmatrix} x_2 + \ldots +
    \begin{pmatrix}
    	a_{1n} \\
    	\vdots \\
    	a_{mn}
    \end{pmatrix} x_n = 
    \begin{pmatrix}
    	b_1 \\
    	\vdots \\
    	b_m.
    \end{pmatrix}
\end{align*}

Тогда решение системы представляется столбцом
\begin{align*}
	x =
	\begin{pmatrix}
		\alpha_1 \\
		\vdots \\
		\alpha_n
	\end{pmatrix}
\end{align*}
и удовлетворяте равенству
\begin{align*}
	\begin{pmatrix}
		a_{11} \\
		\vdots \\
		a_{m1}
	\end{pmatrix} \alpha_1 +
    \begin{pmatrix}
    	a_{12} \\
    	\vdots \\
    	a_{m2}
    \end{pmatrix} \alpha_2 + \ldots + 
    \begin{pmatrix}
    	a_{1n} \\
    	\vdots \\
    	a_{mn}
    \end{pmatrix} \alpha_n =
    \begin{pmatrix}
    	b_1 \\
    	\vdots \\
    	b_m,
    \end{pmatrix}
\end{align*}
т.е. столбец свободных членов $ b $ является линейной комбинацией столбцов матрицы системы.




\section{Теорема (правило) Крамера}

Система называется \textbf{совместной}, если она имеет \emph{хотя бы одно решение}. Система называется \textbf{несовместной}, если она \emph{не имеет ни одного решения}.

Если определитель $ \Delta = \det A $ матрицы системы $ n $ линейный независимых уравнений с $ n $ неизвестными отличен от нуля ($ \det A \neq 0 $), то система имеет \emph{единственное} решение, которое находится по формулам
\begin{align*}
	x_i = \dfrac{ \Delta_i }{ \Delta }, \ i = 1,\ldots, n, \quad (\Delta = \det A \neq 0),
\end{align*}
где $ \Delta_i $ -- определитель матрицы, полученной из матрицы системы $ A = [a_{ij}]_{i,j=1}^n $ заменой $ i $-ого столбца столбцом свободных членов.

ЗАМЕЧАНИЕ: на практике при больших $ n $ правило Крамера не применяется!

Если $ \Delta = 0 $ (матрица коэффициентов системы вырождена) и хотя бы один определитель $ \Delta_i \neq 0 $, то система \emph{несовместна}, т.е. не имеет ни одного решения. Если же $ \Delta = \Delta_1 = \Delta_2 = \ldots, \Delta_n = 0 $, то возможны два случая: либо система несовместна (не имеет ни одного решения), либо система имеет бесконечно много решений \cite[\strbook{188}]{bortakovskiy:2005}.

\section{Условие совместности системы линейных уравнений. Теорема Кронекера-Капелли}

Рассмотрим систему $ m $ линейных уравнений с $ n $ неизвестными. Составим блочную матрицу, приписав к матрице $ A $ справа столбец свободных членов $ b $. Получим \emph{расширенную матрицу системы}
\begin{align*}
	\underset{m \times (n + 1)}{(  A \ | \ b )} =
	  \begin{pmatrix}
	  	  a_{11} & \dots & a_{1n} &  b_1\\
	  	  a_{21} & \dots & a_{2n}  & b_2 \\
	  	  \vdots  & \ddots & \vdots & \vdots \\
	  	  a_{m1} & \dots & a_{mn} & b_m
	  \end{pmatrix}
\end{align*}

Эта матрица содержит всю информацию о системе уравнений, за исключением обозначений неизвестных.

\emph{Теорема Кронекера-Капелли}. Система $ A x = b $ \emph{совместна} (т.е. имеет хотя бы одно решение) тогда и только тогда, когда ранг матрицы системы равен рангу расширенной матрицы $ \rg A = \rg (A \ | \ b) $.

Если $ \rg A \neq \rg (A \ | \ b) $, то система несовместна -- не имеет решений.

Если система имеет решение, то столбец свободных членов есть линейная комбинация столбцов матрицы системы. Поэтому при вычеркивании столбца $ b $ из расширенной матрицы $ (A \ | \ b) $ ее ранг не изменяется. Следовательно, $ \rg (A \ | \ b) = \rg A $.

ЗАМЕЧАНИЕ: теорема Кронекера-Капелли дает лишь критерий существования решения системы, но не указывает способа отыскать этого решения.


\section{Общее решение системы линейных алгебраических уравнений}

Неизвестные, которым соответствуют столбцы, входящие в базисный минор, называются \emph{базисными переменными}, остальные неизвестные -- \emph{свободными переменными}.

\emph{Общее решение} системы, выржающее базисные переменные через свободные, имеет вид \cite[\strbook{192}]{bortakovskiy:2005}
\begin{align*}
	\begin{cases}
		x_1 = b_1^{'} - a_{1, r + 1}^{'} x_{r + 1} - \ldots - a_{1, n}^{'} x_n, \\
		\ldots \\
		x_r = b_r^{'} - a_{r, r + 1}^{'} x_{r + 1} - \ldots - a_{r, n}^{'} x_n,
	\end{cases}
\end{align*}
где $ x_1, x_2, \ldots, x_r $ -- базисные переменные; $ x_{r + 1}, x_{r + 2}, \ldots, x_{n} $ -- свободные переменные.

\emph{Частное решение} системы -- решение системы, получающееся из общего решения, заданием конкретных значений свободными переменным.

Пусть $ x^{н} $ -- решение неоднородной системы. Тогда любое решение $ x $ неоднородной системы можно представить в виде $ x = x^\text{н} + x^\text{о} $, где $ x^\text{о} $ -- решение однородной системы.

Говорят, что \emph{общее решение} неоднородной системы есть сумма \emph{частного решения} \underline{неоднородной} системы и \emph{общего решения} соответствующей \underline{однородной} системы \cite[\strbook{200}]{bortakovskiy:2005}
\begin{align*}
	x = x^\text{н} + C_1 \varphi_1 + C_2 \varphi_2 + \ldots + C_{n - r} \varphi_{n - r}.
\end{align*}


\section{Решение систем уравнений с помощью полуобратных матриц}

Требуется решить систему линейных уравнений
\begin{align*}
	A x = b,
\end{align*}
где $ A $ -- \underline{произвольная} матрица размера $ m \times n $.

Если матрица системы нулевая $ A = O $, то система либо несовместна (при $ b = o $), либо имеет бесконечное множество решений (при $ b = o $ любой подходящий по размерам столбец $ x $ является решением). Далее рассматривается случай ненулевой матрицы $ A $.

Пусть $ A^{\neg 1} $ -- матрица, полуобратная к матрице системы $ A $. Используя определение полуобратной матрицы, неоднородную систему $ Ax = b $ можно переписать так
\begin{align*}
	A A^{\neg 1} A x = b.
\end{align*}

Если $ x $ -- решение системы, то подставляя $ A x = b $ в левую часть последнего соотношения
\begin{align*}
	A A^{\neg 1} A x = b, \quad \rightarrow \quad A A^{\neg 1} b = b.
\end{align*}

Тогда
\begin{align*}
  (E_m - A A^{\neg 1}) \, b = o.
\end{align*}

Это необходимое и достаточное условие совместности системы.

Решением системы будет $ x = A^{\neg 1} b $. Но поскольку \emph{полуобратная матрица} определена \emph{неоднозначно}, то эта формула фактически задает множество решений системы. Преобразуем так, чтобы была видна структура этого множества, в частности, выявим количество независимых параметров
\begin{align*}
  A^{\neg 1}_0 = T \Lambda^T S = T \,
    \begin{pmatrix}
          \begin{array}{c | c}
          	E_r & O \\
          	\hline
          	O & O
          \end{array}
    \end{pmatrix}
    S,
\end{align*}
где $ S $ и $ T $ -- элементарные матрицы порядков $ n $ и $ m $ соответственно, $ \Lambda $ -- матрица простейшего вида, эквивалентная матрице $ A $ ($ \Lambda \sim A $), $ \rg A $.

\emph{Теорема о совместности неоднородной системы и о структуре ее общего решения}. Неоднородная система $ A x = b $ \emph{совместна} тогда и только тогда, когда столбец свободных членов является решением однородной системы $ \Psi b = o $. Если система $ A x = b $ совместна, то ее общее решение имеет вид \cite[\strbook{205}]{bortakovskiy:2005}
\begin{align*}
  x = x^\text{н} + x^\text{о} = A_0^{\neg 1} \, b + \Psi \, c = T
  \begin{pmatrix}
  \begin{array}{c | c}
    E_r & O \\
    \hline 
    O & O
  \end{array}
  \end{pmatrix}
  S \, b + T
  \begin{pmatrix}
    \begin{array}{c}
    	O \\
    	\hline
    	E_{n - r}
    \end{array}
  \end{pmatrix}
  c, \quad
  \Psi =
  \begin{pmatrix}
  	\begin{array}{c | c}
  		O & E_{m - r} S
  	\end{array}
  \end{pmatrix},
\end{align*}
где $ T, S $ -- элементарные преобразующие матрицы, $ c = (C_1 \ldots C_{n - r})^T $ -- столбец произвольных постоянных.

Алгоритм применения полуобратной матрицы:
\begin{enumerate}
	\item Привести матрицу $ A $ системы $ A x = b $ к простейшему виду: $ \Lambda = S A T $. При этом находятся элементраные преобразующие матрицы $ S $ и $ T $, а также ранг $ r = \rg A \geqslant 1 $.
	
	\item Проверить условие совместности системы $ \Psi b = o $. При $ r = m $ система совместна. Если $ r < m $, то составить матрицу $ \Psi = (O \, | \, E_{m - r}) \, S $ и проверить условие $ \Psi b = o $. Если условие выполняется, то система совместна. В противном случае система несовместна и процесс решения заканчивается.
	
	\item Найти частное решение неоднородной системы по формуле
	\begin{align*}
      x^\text{н} = A_o^{\neg 1} \, b = T
        \begin{pmatrix}
        	\begin{array}{c | c}
        		E_r & O \\
        		\hline
        		O & O
        	\end{array}
        \end{pmatrix}
        S \, b
	\end{align*}

    \item Составить фундаментальную матрицу
    \begin{align*}
    	\Phi = T 
    	\begin{pmatrix}
    		\begin{array}{c}
    			O \\
    			\hline
    			E_{n - r}.
    		\end{array}
    	\end{pmatrix}
    \end{align*}

    \item Записать общее решение системы в виде
    \begin{align*}
    	x = x^\text{н} + \Phi \, c,
    \end{align*}
    где $ c = (C_1 \ldots C_{n - r})^T $ -- столбец произвольных постоянных.
\end{enumerate}


\section{Псевдорешения системы линейных уравнений}

Система $ m $ линейных алгебраических уравнений с $ n $ неизвестными $ A x = b $ может иметь единственное решение, бесконечно много решений или вообще не иметь решений. Нужно изменить понятие решения так, чтобы любая система линейных уравнений имела бы единственное в некотором смысле <<решение>>.

Поставим каждому столбцу в соответсвие неотрицательное действительное число, а именно норму (модуль)
$$
| x | = \Big(\sum\limits_{i=1}^{n} x_i^2 \Big)^{1/2}.
$$

\emph{Псевдорешением} системы линейных уравнений называется наименьший по норме столбец $ \tilde{x} $ среди всех столбцов, минимизирующих величину $ |A x - b | $.

ЗАМЕЧАНИЕ: \emph{любая} система имеет единственное псевдорешение \cite[\strbook{209}]{bortakovskiy:2005}
\begin{align*}
	\tilde{x} = A^{\sim 1} b,
\end{align*}
где $ A^{\sim 1} $ -- псевдообратная матрица для матрицы системы.

Понятие псевдорешения позволяет обойти не только факт неединственности, но и факт несуществования решений.

Если система несовместна, то псевдорешение $ \tilde{x} $ обеспечивает наименьшую величину погрешности $ \varepsilon(x) = | A x - b | $.

Если система совместна, то псевдорешение $ \tilde{x} $ является ее решением, т.е. $ \varepsilon(\tilde{x}) = 0 $, причем наименьшим по норме.

Алгоритм нахождения псевдорешения неоднородной системы:
\begin{enumerate}
	\item Найти псевдообратную матрицу $ A^{\sim 1} $.
	
	\item Найти псевдорешение $ \tilde{x} = A^{\sim 1} b $.
\end{enumerate}

ЗАМЕЧАНИЕ: \emph{полуобратная} матрица определена \underline{неоднозначно} и потому задает не конкретное решение, а \emph{множество решений} системы. \emph{Псевдорешение}, полученное с помощью псевдообратной матрицы, всегда вычисляется в \emph{конкретное решение}.


\section{Свойства решений однородной системы}

Общее решение однородной системы $ Ax = o $ имеет вид \cite[\strbook{194}]{bortakovskiy:2005}
\begin{align*}
	\begin{cases}
		x_1 = -a_{1, r + 1}^{'} x_{r + 1} - \ldots - a_{1,n}^{'}x_n,\\
		{\centering \ldots} \\
		x_r = -a_{r, r + 1}^{'} x_{r + 1} - \ldots - a_{r,n}^{'} x_n.
	\end{cases}
\end{align*}

Некоторые свойства:
\begin{itemize}
	\item Если столбцы $ \varphi_1, \varphi_2, \ldots, \varphi_k $ -- решения однородной системы уравнений, то любая их линейная комбинация $ \alpha_1 \, \varphi_1 + \alpha_2 \, \varphi_2 + \ldots + \alpha_k \, \varphi_k $ также является решением однородной системы,
	
	\item Если ранг матрицы однородной системы равен $ r $, то система имеет $ (n - r) $ \emph{линейно независимых решений}.
\end{itemize}

Любая совокупность $ (n - r) $ линейно независимых решений $ \varphi_1, \varphi_2, \ldots, \varphi_{n - r} $ однородной системы называется \emph{фундаментальной системой решений}.

\emph{Теорема об общем решении однородной системы}. Если $ \varphi_1, \varphi_2, \ldots, \varphi_{n - r} $ -- фундаментальная система решений однородной системы уравнений, то столбец
\begin{align}\label{eq:ordinsys}
	x = C_1 \varphi_1 + C_2 \varphi_2 + \ldots + C_{n - r} \varphi_{n - r}
\end{align}
при любых значениях произвольных постоянных $ C_1, C_2, \ldots, C_{n - r} $ также является решением системы $ A x = o $, и, наоборот, для каждого решения $ x $ этой системы найдутся такие значения произвольных постоянных $ C_1, C_2, \ldots, C_{n - r} $, при которых это решение $ x $ удовлетворяет равенству \eqref{eq:ordinsys}.

\section{Функциональные матрицы скалярного аргумента}

\emph{Функциональной матрицей скалярного аргумента} $ t $ называется матрица, элементы которой являются функциями независимой переменной $ t $
\begin{align*}
	\underset{m \times n}{A(t)} = [\, a_{ij}(t) \,]_{i,j=1}^{m,n}
\end{align*}

Производная функциональной матрицы
\begin{align*}
	\underset{m \times n}{\dfrac{d A(t)}{dt}} = \Big[ \dfrac{d a_{ij}(t) }{dt} \Big]_{i,j=1}^{m, n}.
\end{align*}

Производная обратной матрицы (если она существует)
\begin{align*}
	\underset{m \times n}{ \dfrac{d A^{-1}(t)}{dt} } = - A^{-1}(t) \,\dfrac{d A(t)}{dt} \, A^{-1}(t).
\end{align*}

Производная определителя квадратной матрицы $ A(t) $ $ n $-ого порядка
\begin{align*}
	\dfrac{d}{dt} \det A(t) = \sum_{i=1}^{n} \sum_{j=1}^{n} A_{ij}(t) \dfrac{d a_{ij}(t)}{dt} = \tr \Bigg[ A^{+}(t) \, \dfrac{d A(t)}{dt} \Bigg],
\end{align*}
где $ A_{ij}(t) $ -- алгебраическое дополнение элемента $ a_{ij}(t) $ матрицы $ A(t) $; $ A^{+}(t) $ -- присоединенная матрица.


\section{Производные скалярной функции по векторному аргументу}

Рассмотрим скалярную (числовую) функцию нескольких переменных $ f(x_1, x_2, \ldots, x_n) $. Упорядоченный набор переменных $ x_1, x_2, \ldots, x_n $ будем называть \emph{векторным аргументом} этой функции.

\emph{Первый дифференциал} функции $ f(x) = f(x_1, x_2, \ldots, x_n) $ имеет вид
\begin{align*}
	df(x) = \dfrac{ \partial f(x) }{ \partial x_1 } dx_1 + \dfrac{ \partial f(x) }{ \partial x_2 } dx_2 + \ldots + \dfrac{ \partial f(x) }{ \partial x_n } dx_n.
\end{align*}

Сумму в правой части можно представить как произведение строки $ \dfrac{ df(x) }{dx} = \Big( \dfrac{\partial f(x)}{\partial x_1} \ldots \dfrac{\partial f(x)}{\partial x_n} \Big) $ на столбец $ dx = (dx_1 \ldots dx_n)^T $, либо как произведение строки $ dx^T $ на столбец $ dx = \dfrac{ df(x) }{dx^T} = \Big( \dfrac{df(x)}{dx} \Big)^T $.

Так как первый дифференциал $ \underset{1 \times 1}{df(x)} $ -- это одноэлементная матрица (а одноэлементая матрица совпадает со своей транспонированной), то $ \underset{1 \times 1}{df(x)} = \big(\underset{1 \times 1}{df(x)}\big)^T $
\begin{align*}
	\underset{1 \times 1}{df(x)} = \underset{1 \times n}{\dfrac{ df(x) }{ dx }} \, 
	\underset{n \times 1}{dx} = \Big( \dfrac{ df(x) }{dx} dx \Big)^T = dx^T \Big(\dfrac{df(x)}{dx}\Big)^T = \underset{1 \times n}{dx}^T \, \underset{n \times 1}{\dfrac{ df(x) }{dx^T}}.
\end{align*}

\emph{Второй дифференциал} функции имеет вид
\begin{align*}
	d^2f(x) = \sum_{i=1}^{n}\sum_{j=1}^{n} \dfrac{ \partial^2 f(x) }{ \partial x_i \partial x_j } dx_i dx_j.
\end{align*}

Обозначим через $ \dfrac{d^2 f(x)}{dx^T dx} = \Big[ \dfrac{ \partial^2 f(x) }{ \partial x_i^2 \partial x_j^2 } \Big]_{i,j=1}^{n} $ квадратную матрицу частных производных второго порядка (\emph{матрицу Гессе}). Определитель матрицы Гессе называется \emph{гессианом}.

Тогда можно переписать
\begin{align*}
	\underset{1 \times 1}{d^2 f(x)} = \underset{1 \times n}{dx}^T \, \underset{n \times n}{\dfrac{ d^2 f(x) }{ dx^T dx }} \, \underset{n \times 1}{dx}.
\end{align*}

Для скалярной функции скалярного аргумента второй дифференциал будет иметь вид
\begin{align*}
	d^2 f(x) = \dfrac{d^2f(x)}{dx^2}dx^2.
\end{align*}

Для записи производных можно использовать символические векторы (столбцы или строки)
\begin{align*}
	\nabla = \dfrac{d}{dx} = \Big( \dfrac{\partial}{\partial x_1} \ldots \dfrac{\partial}{\partial x_n} \Big), \quad \nabla^T = \dfrac{d}{dx^T} =
	\begin{pmatrix}
		\dfrac{\partial}{\partial x_1} \\
		\vdots\\
		\dfrac{\partial}{\partial x_n}
	\end{pmatrix}.
\end{align*}

При этом дифференциирование функции формально записывается как как умножение функции на символический вектор производных. Например, градиент функции есть произведение вектора $ \nabla $ на функцию $ f(x) $
\begin{align*}
	\nabla f(x_1, \ldots, x_n) = \Big( \dfrac{ \partial f }{ \partial x_1 } \ldots \dfrac{ \partial f }{ \partial x_n }  \Big), \\
	\underset{n \times 1}{\nabla}^T \underset{1 \times n }{\nabla} =
	\begin{pmatrix}
		\dfrac{ \partial }{ \partial x_1 }\\
		\ldots \\
		\dfrac{ \partial }{ \partial x_n }
	\end{pmatrix}
    \Big( \dfrac{\partial}{\partial x_1} \ldots \dfrac{\partial}{\partial x_n} \Big) = \Bigg[ \dfrac{\partial^2}{\partial x_i \partial x_j} \Bigg]_{i, j=1}^n.
\end{align*}

Найти первую и вторую производные сложной функции $ g(t) = f(x_1(t), \ldots, x_n(t)) $, применяя матричные обозначения.

Находим производные функции, заменяя суммирование операциями умножения соответствующих матриц. Первая производная
\begin{align*}
	\dfrac{ d g(t) }{ dt } = \dfrac{d}{dt} \Big( f(x_1(t), \ldots, x_n(t))) \Big) = \sum_{i=1}^{n} \dfrac{\partial f(x(t))}{\partial x_i} \cdot \dfrac{ d x_i(t) }{dt} = \dfrac{df(x(t))}{dx} \cdot \dfrac{dx(t)}{dt}
\end{align*}

В случае скалярной функции скалярного аргумента первая производная от функции $ g(x) $ будет выглядеть так же.

Вторая производная скалярной функции векторного аргумента
\begin{multline*}
  \dfrac{d^2 g(t)}{dt^2} = \sum_{j=1}^{n} \sum_{i=1}^{n} \dfrac{ \partial^2 f(x(t)) }{ \partial x_j \partial x_i } \cdot \dfrac{ d x_i(t) }{ dt } \cdot \dfrac{ d x_j(t) }{dt} + \sum_{i=1}^n \dfrac{ \partial f(x(t)) }{\partial x_i} \cdot \dfrac{d x_i^2}{d t^2} = \ldots \\
  \ldots = \Big( \dfrac{d x(t)}{dt} \Big)^T \dfrac{ d^2 f(x(t)) }{ dx^T dx } \cdot \dfrac{dx(t)}{dt} + \dfrac{df(x(t))}{dx} \cdot \dfrac{d^2 x(t)}{dt^2}.
\end{multline*}

В случае скалярной функции скалярного аргумента вторая производная будет выглядеть так
\begin{align*}
  \dfrac{d^2 g(t)}{d t^2} = \dfrac{ d^2 f(x(t)) }{dx^2} \Big( \dfrac{dx(t)}{dt} \Big)^2 + \dfrac{ df(x(t)) }{dx} \cdot \dfrac{ d^2 x(t) }{dt^2}.
\end{align*}

Выражения для первой производной совпадают, а для второй производной -- отличаются незначительно, причем полное совпадение будет, если учесть, что $ x^T = x $ для \emph{скалярной} величины $ x $.

\section{Производные от векторной функции векторного аргумента}

Пусть задан столбец
$$
f(x) =
\begin{pmatrix}
	f_1(x_1, \ldots, x_n)\\
	\vdots \\
	f_n(x_1, \ldots, x_n)
\end{pmatrix}
$$
функций нескольких переменных (говорят, что задана \emph{вектор-функция векторного аргумента}).

Первый дифференциал вектор-функции имеет вид
\begin{align*}
	df(x) =
	\begin{pmatrix}
		df_1(x_1, \ldots, x_n) \\
		\vdots \\
		df_m(x_1, \ldots, x_n)
	\end{pmatrix}
	=
	\begin{pmatrix}
		\sum\limits_{j=1}^{n} \dfrac{\partial f_1(x_1, \ldots, x_n)}{\partial x_j} \, dx_j\\
		\vdots \\
		\sum\limits_{j=1}^{n} \dfrac{\partial f_m(x_1, \ldots, x_n)}{\partial x_j} \, dx_j
	\end{pmatrix} = \sum_{j=1}^{n}
    \begin{pmatrix}
    	\dfrac{\partial f_1(x)}{\partial x_j} \\
    	\vdots \\
    	\dfrac{\partial f_m(x)}{\partial x_j} 
    \end{pmatrix}
    dx_j
\end{align*}

Обозначим через
\begin{align*}
	\dfrac{df(x)}{dx} =
	\begin{pmatrix}
		\dfrac{\partial f_1(x)}{\partial x_1} & \ldots & \dfrac{\partial f_1(x)}{\partial x_n} \\
		\vdots & \ddots & \vdots \\
		\dfrac{\partial f_m(x)}{\partial x_1} & \ldots & \dfrac{\partial f_m(x)}{\partial x_n}
	\end{pmatrix} =
    \Bigg[ \dfrac{\partial f_i(x)}{\partial x_j} \Bigg]_{i,j=1}^{m, n}
\end{align*}
матрицу частных производных первого порядка заданных функций (\emph{матрицу Якоби}).

Тогда выражение для первого дифференциала можно записать в виде $ df(x) = \dfrac{df(x)}{dx} dx $, т.е. $ \dfrac{df(x)}{dx} $ -- производная вектор-функции векторного аргумента.

Как и в случае с аргументом $ x $, упорядоченный набор функций можно считать не матрицей-столбцом, а матрицей-строкой $ (f(x))^T $. Этот случай сводится к предыдущему, учитывая, что операции дифференциирования и транспонирования можно выполнять в любом порядке, так как $ d(f^T) = (df)^T $. Тогда из равенства $ df = \dfrac{df}{dx}dx $ получаем $ df^T = (dx)^T \Big( \dfrac{df}{dx} \Big)^T = (dx)^T \dfrac{df^T}{dx^T} $, где
\begin{align*}
	\Big( \dfrac{df(x)}{dx}\Big)^T = \dfrac{df^T}{dx^T} =
	\begin{pmatrix}
		\dfrac{\partial f_1(t)}{\partial x_1} & \ldots & \dfrac{\partial f_m(x)}{\partial x_1} \\
		\vdots & \ddots & \vdots \\
		\dfrac{\partial f_1(x)}{\partial x_n} & \ldots & \dfrac{\partial f_m(x)}{\partial x_n}
	\end{pmatrix}
\end{align*}
-- транспонированная матрица Якоби вектор-функции векторного аргумента.

\section{Правила дифференциирования по векторному аргументу}

Векторный аргумент $ x $, его приращение $ dx $ считаем вектор-столбцами размеров $ n \times 1 $.

Первый дифференциал скалярной функции векторного аргумента $ f(x_1, \ldots, x_n) $ (одноэлементная матрица) имеет вид
\begin{align*}
	df = \dfrac{df}{dx} \, dx = dx^T \, \dfrac{df}{dx^T},
\end{align*}
где $ \dfrac{df}{dx} = \Big( \dfrac{df}{dx_1} \ldots \dfrac{df}{dx_n} \Big) $ -- градиент функции, а $ \Big( \dfrac{df}{dx} \Big)^T = \dfrac{df}{dx^T} $, так как функция скалярная.

Второй дифференциал скалярной функции векторного аргумента $ f(x_1, \ldots, x_n) $
\begin{align*}
	d^2 f = dx^T \dfrac{d^2 f}{dx^T dx} dx,
\end{align*}
где $ \dfrac{d^2 f}{dx^T dx} = \Bigg[ \dfrac{\partial^2 f(x)}{\partial x_i \partial x_j} \Bigg]_{i,j=1}^{n} $ -- матрица Гессе.

Первый дифференциал вектор-функции векторного аргумента (вектора-столбца) $ f(x) $ имеет вид
\begin{align*}
	df = \dfrac{df(x)}{dx} dx,
\end{align*}
где $ \dfrac{df(x)}{dx} $ -- матрица Якоби.

Первый дифференциал вектора-строки
\begin{align*}
	(df)^T = d(f^T) = dx^T \dfrac{df^T}{dx^T}.
\end{align*}

В частном случае, когда $ f(x_1, \ldots, x_n) = (x_1, \ldots, x_n) $, получаем
\begin{align*}
	\dfrac{dx}{dx} = E, \quad \dfrac{dx^T}{dx^T} = E,
\end{align*}
где $ E $ -- единичная матрица $ n $-ого порядка.

Числовую матрицу $ C $ соответствующих размеров можно выносить за знак производной
\begin{align*}
	\dfrac{d(Cf)}{dx} = C \, \dfrac{df}{dx}, \quad \dfrac{d(f^T C)}{dx^T} = \dfrac{df^T}{dx^T} \, C
\end{align*}

Производные суммы, разности и произведения вектор-функций векторного аргумента $ u(x) $ и $ v(x) $ одинаковых размеров $ m \times 1 $
\begin{align*}
	\dfrac{d(u + v)}{dx} = \dfrac{du}{dx} + \dfrac{dv}{dx}, \quad \dfrac{d(u - v)}{dx} = \dfrac{du}{dx} - \dfrac{dv}{dx}, \\
	\dfrac{d(u^T v)}{dx} = u^T \dfrac{dv}{dx} + v^T \dfrac{du}{dx}, \quad \dfrac{d(u^T v)}{dx^T} = \dfrac{du^T}{dx^T} v + \dfrac{d v^T}{dx^T} u.
\end{align*}

Производная сложной функции $ z(y(x)) $, где $
z = z(y) = 
\begin{pmatrix}
	z_1(y) \\
	\vdots \\
	z_k(y)
\end{pmatrix}
$ и $
y = y(x) = 
\begin{pmatrix}
	y_1(x) \\
	\vdots \\
	y_m(x)
\end{pmatrix}
$, вычисляется по формуле $ \dfrac{dz(y(x))}{dx} = \dfrac{dz(y(x))}{dy} \, \dfrac{dy(x)}{dx} $ или, опуская аргументы, $ \dfrac{dz}{dx} = \underset{k \times m}{\dfrac{dz}{dy}} \, \underset{m \times n}{\dfrac{dy}{dx}} $.

След матрицы Якоби (при $ m = n $) определяет \emph{дивергенцию}
\begin{align*}
	\divv f = \tr \dfrac{df}{dx} = \sum_{i=1}^n \dfrac{\partial f_i}{\partial x_i},
\end{align*}
где $ f(x) $ -- векторная функция векторного аргумента.

\section{Производные матричной функции по векторному аргументу}

Рассмотрим функциональную матрицу $ A(x) $, элементами которой служат скалярные функции $ a_{ij}(x) $ векторного аргумента $ x $. То есть такая матрица представляет собой трехмерную сущность, в которой на пересечении строки и столбца стоит скалярная функция, имеющая <<глубину>> в виде вектора аргументов.

Первый дифференциал этой функции
\begin{align*}
	d A(x) = \sum_{i=1}^n \dfrac{\partial A(x)}{\partial x_i} dx_i,
\end{align*}
где $ \dfrac{\partial A(x)}{\partial x_i} $ -- частная производная матрицы по одной переменной.

Совокупность частных производных (градиент функциональной матрицы) представляет собой объект, элементы которого $ \dfrac{\partial a_{ij}(x)}{\partial x_k} $ нумеруются тремя индексами: номер строки, номер столбца и номер переменной дифференциирования. Поэтому заменить операцию суммирования в правой части формулы операцией умножения матриц в данном случае не представляется возможным. Необходимо вводить тензоры и операции над ними.

Элементы матрицы $ A = (a_j^i) $ обозначаются $ a_j^i $, где $ i $ -- номер строки, а $ j $ -- номер столбца. В частности, $ x = (x^i) $ -- столбец, а $ y = (y_j) $ -- строка.

Частную производную функции $ F(x) $ (склалярной, векторной или матричной), то по ним производится суммирование (хотя знак суммы не указывается). Например, если $ A = (a_j^i) $ -- матрица размеров $ m \times n $, $ x = (x^j) $ -- столбец размеров $ n \times 1 $, $ y = (y_i) $ -- строка размеров $ 1 \times m $, то
\begin{align*}
	a_j^i x^j = \sum_{j=1}^n a_j^i x^j, \quad a_j^i y_i = \sum_{i=1}^m a_j^i y_i, \quad a_j^ix^jy_i = \sum_{i=1}^m\sum_{j=1}^n a_j^i x^jy_i,
\end{align*}
т.е. $ a_j^i x^j $ -- $ i $-ый элемент столбца $ A x $; $ a_j^i y_i $ -- $ j $-ый элемент строки $ yA $; $ a_j^i x^jy_i $ -- число $ yAx $.

Применяя эти соглашения, запишем дифференциалы
\begin{align*}
	df = f_{(i)}dx^i, \quad d^2 f = f_{(i)(j)}dx^idx^j,\\
	df^i = f_{(j)}^i dx^j, \\
	df_j^i = f_{j(k)}^i dx^k,
\end{align*}
где $ f_{j(k)}^i = \dfrac{\partial f_j^i}{\partial x^k} $ -- частная производная первого порядка элемента $ f_j^i $ функциональной матрицы $ F $ по переменной $ x^k $.

\section{Линейные и квадратичные формы}

Многочлен первой степени от $ n $ переменных $ x_1, \ldots, x_n $ называется выражением вида
\begin{align*}
	p_1(x) = c_1 x_1 + c_2 x_2 + \ldots + c_n x_n + c_0,
\end{align*}
где $ c_0, c_1, \ldots, c_n $ -- коэффициенты многочлена (предполагается, что среди коэффициентов есть отличные от нуля); коэффициент $ c_0 $ называется свободным членом. Многочлен перовой степени называется однородным, если $ p_1(\lambda x) = \lambda p_1 (x) $ для любого числа $ \lambda $ (это возможно только когда $ c_0 = 0 $).

\emph{Линейной формой} переменных $ x_1, \ldots, x_n $ называется однородный многочлен первой степени
\begin{align*}
	g(x) = \sum_{i=1}^n c_i x_i,
\end{align*}
где $ \{c_i\}_{i=1}^n $ -- коэффициенты линейной формы. 

Составляя из коэффициентов строку $ c = (c_1 \ldots c_n) $, а из переменных -- столбец $ x = (x_1 \ldots x_n)^T $, линейную форму можно записать в виде
\begin{align*}
	g(x) = cx.
\end{align*}

Многочлен второй степени от $ n $ переменных $ x_1, \ldots, x_n $ называется выражение
$$
p_2(x) = \sum_{i=1}^n\sum_{j=1}^m a_{ij}x_ix_j + \sum_{i=1}^n b_i x_i + c_0,
$$
где числа $ a_{ij}, b_i, c_0 $ -- коэффициенты многочлена: $ a_{ij} $ -- страшие коэффициенты; $ b_i $ -- коэффициенты линейных членов; $ c_0 $ -- свободный член.

Многочлен второй степени называется однородным, если $ p_2(\lambda x) = \lambda^2 p_2(x) $ (это возможно только когда $ b_1 = b_2 = \ldots = b_n = 0, c_0 = 0 $).

\emph{Квадратичной формой} переменных $ x_1, \ldots, x_n $ называется однородный многочлен второй степени
\begin{align*}
	q(x) = \sum_{i=1}^n \sum_{j=1}^n a_{ij}x_i x_j, \quad a_{ij} = a_{ji}.
\end{align*}

Симметрическая матрица $ A = (a_{ij}) $, составленная из коэффициентов квадратичной формы, называется \emph{матрицей квадратичной формы}.

Квадратичная форма называется \emph{вырожденной}, если ее матрица вырожденая ($ \rg A < n $), в противном случае, когда матрица невырожденная ($ \rg A = n $), квадратичная форма называется \emph{невырожденной}.

Составляя из переменных столбец $ x = (x_1 \ldots x_n)^T $, квадратичную форму можно записать в виде
\begin{align*}
	q(x) = x^T A x.
\end{align*}




% Источники в "Газовой промышленности" нумеруются по мере упоминания 
\begin{thebibliography}{99}\addcontentsline{toc}{section}{Список литературы}
	\bibitem{bortakovskiy:2005}{\emph{Бортаковский А.С.} Линейная алгебра в примерах и задачах. -- М.: Высш. шк., 2005. -- 591~с.}
	
	\bibitem{gmurman:1972}{\emph{Гмурман В.Е.} Теория вероятностей и математическая статистика. -- М.: Высшая школа, 1972.~-- 368~с. }
	
	\bibitem{bahvalov:num_methods}{\emph{Бахвалов Н. С.} Численные методы. -- М.: Лаборатория Базовых Знаний, 2000.~--624 ~с.}
	
	\bibitem{lagutin:2009}{\emph{Лагутин М.Б.} Наглядная математическая статистика. -- М.: БИНОМ, 2009.~-- 472~с. }
	
	\bibitem{kobzar:2012}{\emph{Кобзарь А.И.} Прикладная математическая статистика. Для инженеров и научных работников. -- М.: ФИЗМАТЛИТ, 2012.~-- 816~с. }
\end{thebibliography}

\end{document}
